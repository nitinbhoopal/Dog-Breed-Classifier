{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "from os import listdir, makedirs\n",
    "from os.path import join, exists, expanduser\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import log_loss, accuracy_score\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.applications import xception\n",
    "from keras.applications import inception_v3\n",
    "from keras.applications.vgg16 import preprocess_input, decode_predictions\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import os\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10222 10222\n",
      "10357\n"
     ]
    }
   ],
   "source": [
    "#Since there are too many images and image classes, we'll consider only the top 16 classes\n",
    "INPUT_SIZE = 300\n",
    "NUM_CLASSES = 16\n",
    "SEED = 1987\n",
    "data_dir = os.getcwd()\n",
    "labels = pd.read_csv(join(data_dir, 'labels.csv'))\n",
    "print(len(listdir(join(data_dir, 'train'))), len(labels))\n",
    "print(len(listdir(join(data_dir, 'test'))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_breed_list = list(labels.groupby('breed').count().sort_values(by='id', ascending=False).head(NUM_CLASSES).index)\n",
    "labels = labels[labels['breed'].isin(selected_breed_list)]\n",
    "labels['target'] = 1\n",
    "labels['rank'] = labels['breed'].rank(ascending=0,method='dense')\n",
    "labels_pivot = labels.pivot('id', 'breed', 'target').reset_index().fillna(0)\n",
    "np.random.seed(seed=SEED)\n",
    "rnd = np.random.random(len(labels))\n",
    "train_idx = rnd < 0.8\n",
    "valid_idx = rnd >= 0.8\n",
    "y_train_val = labels_pivot[selected_breed_list].values\n",
    "y_train = y_train_val[train_idx]\n",
    "y_val = y_train_val[valid_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reads and resizes the image, train_or_test is a string: \"train\"/\"test\"\n",
    "def read_img(img_id, train_or_test, size):\n",
    "    img = image.load_img(join(data_dir, train_or_test, '%s.jpg' % img_id), target_size=size)\n",
    "    img = image.img_to_array(img)\n",
    "    img = img/255.0\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1777it [00:08, 205.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Images shape: (1777, 300, 300, 3) size: 479,790,000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "x_train_val = np.zeros((len(labels), INPUT_SIZE, INPUT_SIZE, 3), dtype='float32')\n",
    "for i, img_id in tqdm(enumerate(labels['id'])):\n",
    "    img = read_img(img_id, 'train', (INPUT_SIZE, INPUT_SIZE))\n",
    "    x = preprocess_input(np.expand_dims(img.copy(), axis=0))\n",
    "    x_train_val[i] = x\n",
    "print('Train Images shape: {} size: {:,}'.format(x_train_val.shape, x_train_val.size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((1409, 300, 300, 3), (368, 300, 300, 3), (1409, 16), (368, 16))\n",
      "1409/1409 [==============================] - 19s 13ms/sample\n",
      "368/368 [==============================] - 6s 15ms/sample\n",
      "VGG train bottleneck features shape: (1409, 512) size: 721,408\n",
      "VGG valid bottleneck features shape: (368, 512) size: 188,416\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications import VGG16\n",
    "x_train = x_train_val[train_idx]\n",
    "x_val = x_train_val[valid_idx]\n",
    "print((x_train.shape, x_val.shape, y_train.shape, y_val.shape))\n",
    "vgg_bottleneck = VGG16(weights='imagenet', include_top=False, pooling='avg')\n",
    "train_vgg_bf = vgg_bottleneck.predict(x_train, batch_size=32, verbose=1)\n",
    "valid_vgg_bf = vgg_bottleneck.predict(x_val, batch_size=32, verbose=1)\n",
    "print('VGG train bottleneck features shape: {} size: {:,}'.format(train_vgg_bf.shape, train_vgg_bf.size))\n",
    "print('VGG valid bottleneck features shape: {} size: {:,}'.format(valid_vgg_bf.shape, valid_vgg_bf.size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression(multi_class='multinomial', solver='lbfgs', random_state=SEED,max_iter = 9000)\n",
    "logreg.fit(train_vgg_bf, (y_train * range(NUM_CLASSES)).sum(axis=1))\n",
    "valid_probs = logreg.predict_proba(valid_vgg_bf)\n",
    "valid_preds = logreg.predict(valid_vgg_bf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation VGG LogLoss 2.647898018386328\n",
      "Validation VGG Accuracy 0.13858695652173914\n"
     ]
    }
   ],
   "source": [
    "print('Validation VGG LogLoss {}'.format(log_loss(y_val, valid_probs)))\n",
    "print('Validation VGG Accuracy {}'.format(accuracy_score((y_val*range(NUM_CLASSES)).sum(axis=1), valid_preds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((1409, 300, 300, 3), (368, 300, 300, 3), (1409, 16), (368, 16))\n",
      "1409/1409 [==============================] - 9s 6ms/sample\n",
      "368/368 [==============================] - 2s 6ms/sample\n",
      "InceptionV3 train bottleneck features shape: (1409, 2048) size: 2,885,632\n",
      "InceptionV3 valid bottleneck features shape: (368, 2048) size: 753,664\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "x_train = x_train_val[train_idx]\n",
    "x_val = x_train_val[valid_idx]\n",
    "print((x_train.shape, x_val.shape, y_train.shape, y_val.shape))\n",
    "inception_bottleneck = InceptionV3(weights='imagenet', include_top=False, pooling='avg')\n",
    "train_i_bf = inception_bottleneck.predict(x_train, batch_size=32, verbose=1)\n",
    "valid_i_bf = inception_bottleneck.predict(x_val, batch_size=32, verbose=1)\n",
    "print('InceptionV3 train bottleneck features shape: {} size: {:,}'.format(train_i_bf.shape, train_i_bf.size))\n",
    "print('InceptionV3 valid bottleneck features shape: {} size: {:,}'.format(valid_i_bf.shape, valid_i_bf.size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression(multi_class='multinomial', solver='lbfgs', random_state=SEED,max_iter = 9000)\n",
    "logreg.fit(train_i_bf, (y_train * range(NUM_CLASSES)).sum(axis=1))\n",
    "valid_probs = logreg.predict_proba(valid_i_bf)\n",
    "valid_preds = logreg.predict(valid_i_bf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Inception LogLoss 2.2721441854592306\n",
      "Validation Inception Accuracy 0.30434782608695654\n"
     ]
    }
   ],
   "source": [
    "print('Validation Inception LogLoss {}'.format(log_loss(y_val, valid_probs)))\n",
    "print('Validation Inception Accuracy {}'.format(accuracy_score((y_val * range(NUM_CLASSES)).sum(axis=1), valid_preds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
